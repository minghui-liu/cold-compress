{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import csv\n",
    "import json\n",
    "import os\n",
    "\n",
    "\n",
    "task = 'gsm'\n",
    "\n",
    "# FastGen\n",
    "strategy = 'fastgen'\n",
    "root = 'ICLR/results_fastgen/results/Meta-Llama-3-8B-Instruct/hybrid/'\n",
    "subdir_template = 'cache_bits=None__cache_length_pattern=tile__cache_strategy_pattern=tile__global_tokens=4__hybrid_strategies=specialx1,special_puncx1,special_punc_heavy_hitterx1,special_punc_heavy_hitter_windowx1,fullx1__max_cache_length=1__min_recovery_frac={frac}'\n",
    "fastgen_df = []\n",
    "\n",
    "for frac in [0.1, 0.3, 0.5, 0.7, 0.9]:\n",
    "    subdir = subdir_template.format(frac=frac)\n",
    "    task_json = os.path.join(root, subdir, f'{task}_metrics.json')\n",
    "    with open(task_json) as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    # get the metrics\n",
    "    bert_precision = data['BertScore_precision']\n",
    "    bert_recall = data['BertScore_recall']\n",
    "    bert_f1 = data['BertScore_f1']\n",
    "    rouge_1 = data['Rouge_rouge1']\n",
    "    rouge_2 = data['Rouge_rouge2']\n",
    "    rouge_L = data['Rouge_rougeL']\n",
    "    rouge_Lsum = data['Rouge_rougeLsum']\n",
    "    chatgpt_rouge = data['ChatGPT-Rouge_chatgpt_rouge']\n",
    "    chatgpt_coherent = data['ChatGPTJudge_coherent']\n",
    "    chatgpt_faithful = data['ChatGPTJudge_faithful']\n",
    "    chatgpt_helpful = data['ChatGPTJudge_helpful']\n",
    "    cache_mem_gb = data['cache_memory_gb']\n",
    "    compress_ratio = data['compression_ratio_avg']\n",
    "    decode_toks_per_sec_top_10p = data['decode_toks_per_sec_top_10p']\n",
    "    cache_size = frac\n",
    "\n",
    "    fastgen_df.append({\n",
    "        'strategy': strategy,\n",
    "        'cache_size': cache_size,\n",
    "        'bert_precision': bert_precision,\n",
    "        'bert_recall': bert_recall,\n",
    "        'bert_f1': bert_f1,\n",
    "        'rouge_1': rouge_1,\n",
    "        'rouge_2': rouge_2,\n",
    "        'rouge_L': rouge_L,\n",
    "        'rouge_Lsum': rouge_Lsum,\n",
    "        'chatgpt_rouge': chatgpt_rouge,\n",
    "        'chatgpt_coherent': chatgpt_coherent,\n",
    "        'chatgpt_faithful': chatgpt_faithful,\n",
    "        'chatgpt_helpful': chatgpt_helpful,\n",
    "        'compress_ratio_avg': compress_ratio,\n",
    "        'cache_mem_gb': cache_mem_gb,\n",
    "        'decode_toks_per_sec_top_10p': decode_toks_per_sec_top_10p,\n",
    "    })\n",
    "\n",
    "fastgen_df = pd.DataFrame(fastgen_df)\n",
    "fastgen_df.to_csv(f'ICLR/fastgen_{task}.csv', index=False)\n",
    "\n",
    "# Scissorhands\n",
    "strategy = 'scissorhands'\n",
    "root = 'ICLR/results_nov_15/results/Meta-Llama-3-8B-Instruct/heavy_hitter/'\n",
    "subdir_template = 'attn_thresholding=True__cache_bits=None__cache_length_pattern=tile__cache_strategy_pattern=tile__global_tokens=4__history_window_size=400__max_cache_length={frac}__recent_window=10'\n",
    "scissorhands_df = []\n",
    "\n",
    "for frac in [0.1, 0.3, 0.5, 0.7, 0.9]:\n",
    "    subdir = subdir_template.format(frac=frac)\n",
    "    task_json = os.path.join(root, subdir, f'{task}_metrics.json')\n",
    "    with open(task_json) as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    # get the metrics\n",
    "    bert_precision = data['BertScore_precision']\n",
    "    bert_recall = data['BertScore_recall']\n",
    "    bert_f1 = data['BertScore_f1']\n",
    "    rouge_1 = data['Rouge_rouge1']\n",
    "    rouge_2 = data['Rouge_rouge2']\n",
    "    rouge_L = data['Rouge_rougeL']\n",
    "    rouge_Lsum = data['Rouge_rougeLsum']\n",
    "    chatgpt_rouge = data['ChatGPT-Rouge_chatgpt_rouge']\n",
    "    chatgpt_coherent = data['ChatGPTJudge_coherent']\n",
    "    chatgpt_faithful = data['ChatGPTJudge_faithful']\n",
    "    chatgpt_helpful = data['ChatGPTJudge_helpful']\n",
    "    cache_mem_gb = data['cache_memory_gb']\n",
    "    compress_ratio = data['compression_ratio_avg']\n",
    "    decode_toks_per_sec_top_10p = data['decode_toks_per_sec_top_10p']\n",
    "    cache_size = frac\n",
    "\n",
    "    scissorhands_df.append({\n",
    "        'strategy': strategy,\n",
    "        'cache_size': cache_size,\n",
    "        'bert_precision': bert_precision,\n",
    "        'bert_recall': bert_recall,\n",
    "        'bert_f1': bert_f1,\n",
    "        'rouge_1': rouge_1,\n",
    "        'rouge_2': rouge_2,\n",
    "        'rouge_L': rouge_L,\n",
    "        'rouge_Lsum': rouge_Lsum,\n",
    "        'chatgpt_rouge': chatgpt_rouge,\n",
    "        'chatgpt_coherent': chatgpt_coherent,\n",
    "        'chatgpt_faithful': chatgpt_faithful,\n",
    "        'chatgpt_helpful': chatgpt_helpful,\n",
    "        'compress_ratio_avg': compress_ratio,\n",
    "        'cache_mem_gb': cache_mem_gb,\n",
    "        'decode_toks_per_sec_top_10p': decode_toks_per_sec_top_10p,\n",
    "    })\n",
    "\n",
    "scissorhands_df = pd.DataFrame(scissorhands_df)\n",
    "scissorhands_df.to_csv(f'ICLR/scissorhands_{task}.csv', index=False)\n",
    "\n",
    "# H2O\n",
    "strategy = 'h2o'\n",
    "root = 'ICLR/results_nov_15/results/Meta-Llama-3-8B-Instruct/heavy_hitter/'\n",
    "subdir_template = 'attn_thresholding=False__cache_bits=None__cache_length_pattern=tile__cache_strategy_pattern=tile__global_tokens=4__history_window_size=1__max_cache_length={frac}__recent_window=10'\n",
    "h2o_df = []\n",
    "for frac in [0.1, 0.3, 0.5, 0.7, 0.9]:\n",
    "    subdir = subdir_template.format(frac=frac)\n",
    "    task_json = os.path.join(root, subdir, f'{task}_metrics.json')\n",
    "    with open(task_json) as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    # get the metrics\n",
    "    bert_precision = data['BertScore_precision']\n",
    "    bert_recall = data['BertScore_recall']\n",
    "    bert_f1 = data['BertScore_f1']\n",
    "    rouge_1 = data['Rouge_rouge1']\n",
    "    rouge_2 = data['Rouge_rouge2']\n",
    "    rouge_L = data['Rouge_rougeL']\n",
    "    rouge_Lsum = data['Rouge_rougeLsum']\n",
    "    chatgpt_rouge = data['ChatGPT-Rouge_chatgpt_rouge']\n",
    "    chatgpt_coherent = data['ChatGPTJudge_coherent']\n",
    "    chatgpt_faithful = data['ChatGPTJudge_faithful']\n",
    "    chatgpt_helpful = data['ChatGPTJudge_helpful']\n",
    "    cache_mem_gb = data['cache_memory_gb']\n",
    "    compress_ratio = data['compression_ratio_avg']\n",
    "    decode_toks_per_sec_top_10p = data['decode_toks_per_sec_top_10p']\n",
    "    cache_size = frac\n",
    "\n",
    "    h2o_df.append({\n",
    "        'strategy': strategy,\n",
    "        'cache_size': cache_size,\n",
    "        'bert_precision': bert_precision,\n",
    "        'bert_recall': bert_recall,\n",
    "        'bert_f1': bert_f1,\n",
    "        'rouge_1': rouge_1,\n",
    "        'rouge_2': rouge_2,\n",
    "        'rouge_L': rouge_L,\n",
    "        'rouge_Lsum': rouge_Lsum,\n",
    "        'chatgpt_rouge': chatgpt_rouge,\n",
    "        'chatgpt_coherent': chatgpt_coherent,\n",
    "        'chatgpt_faithful': chatgpt_faithful,\n",
    "        'chatgpt_helpful': chatgpt_helpful,\n",
    "        'compress_ratio_avg': compress_ratio,\n",
    "        'cache_mem_gb': cache_mem_gb,\n",
    "        'decode_toks_per_sec_top_10p': decode_toks_per_sec_top_10p,\n",
    "    })\n",
    "\n",
    "h2o_df = pd.DataFrame(h2o_df)\n",
    "h2o_df.to_csv(f'ICLR/h2o_{task}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = 'gsm_mc'\n",
    "\n",
    "# FastGen\n",
    "strategy = 'fastgen'\n",
    "root = 'ICLR/results_fastgen/results/Meta-Llama-3-8B-Instruct/hybrid/'\n",
    "subdir_template = 'cache_bits=None__cache_length_pattern=tile__cache_strategy_pattern=tile__global_tokens=4__hybrid_strategies=specialx1,special_puncx1,special_punc_heavy_hitterx1,special_punc_heavy_hitter_windowx1,fullx1__max_cache_length=1__min_recovery_frac={frac}'\n",
    "fastgen_df = []\n",
    "\n",
    "for frac in [0.1, 0.3, 0.5, 0.7, 0.9]:\n",
    "    subdir = subdir_template.format(frac=frac)\n",
    "    task_json = os.path.join(root, subdir, f'{task}_metrics.json')\n",
    "    with open(task_json) as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    # get the metrics\n",
    "    acc = data['Accuracy']\n",
    "    exact_match = data['ExactMatch']\n",
    "    cache_mem_gb = data['cache_memory_gb']\n",
    "    compress_ratio = data['compression_ratio_avg']\n",
    "    decode_toks_per_sec_top_10p = data['decode_toks_per_sec_top_10p']\n",
    "\n",
    "    fastgen_df.append({\n",
    "        'strategy': strategy,\n",
    "        'cache_size': frac,\n",
    "        'accuracy': acc,\n",
    "        'exact_match': exact_match,\n",
    "        'compress_ratio_avg': compress_ratio,\n",
    "        'cache_mem_gb': cache_mem_gb,\n",
    "        'decode_toks_per_sec_top_10p': decode_toks_per_sec_top_10p,\n",
    "    })\n",
    "\n",
    "fastgen_df = pd.DataFrame(fastgen_df)\n",
    "fastgen_df.to_csv(f'ICLR/fastgen_{task}.csv', index=False)\n",
    "\n",
    "# Scissorhands\n",
    "strategy = 'scissorhands'\n",
    "root = 'ICLR/results_scissorhands/results/Meta-Llama-3-8B-Instruct/heavy_hitter/'\n",
    "subdir_template = 'attn_thresholding=True__cache_bits=None__cache_length_pattern=tile__cache_strategy_pattern=tile__global_tokens=4__history_window_size=400__max_cache_length={frac}__recent_window=10'\n",
    "scissorhands_df = []\n",
    "\n",
    "for frac in [0.1, 0.3, 0.5, 0.7, 0.9]:\n",
    "    subdir = subdir_template.format(frac=frac)\n",
    "    task_json = os.path.join(root, subdir, f'{task}_metrics.json')\n",
    "    with open(task_json) as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    # get the metrics\n",
    "    acc = data['Accuracy']\n",
    "    exact_match = data['ExactMatch']\n",
    "    cache_mem_gb = data['cache_memory_gb']\n",
    "    compress_ratio = data['compression_ratio_avg']\n",
    "    decode_toks_per_sec_top_10p = data['decode_toks_per_sec_top_10p']\n",
    "\n",
    "    scissorhands_df.append({\n",
    "        'strategy': strategy,\n",
    "        'cache_size': frac,\n",
    "        'accuracy': acc,\n",
    "        'exact_match': exact_match,\n",
    "        'compress_ratio_avg': compress_ratio,\n",
    "        'cache_mem_gb': cache_mem_gb,\n",
    "        'decode_toks_per_sec_top_10p': decode_toks_per_sec_top_10p,\n",
    "    })\n",
    "\n",
    "scissorhands_df = pd.DataFrame(scissorhands_df)\n",
    "scissorhands_df.to_csv(f'ICLR/scissorhands_{task}.csv', index=False)\n",
    "\n",
    "\n",
    "# H2O\n",
    "strategy = 'h2o'\n",
    "root = 'ICLR/results_h2o/results/Meta-Llama-3-8B-Instruct/heavy_hitter/'\n",
    "subdir_template = 'attn_thresholding=False__cache_bits=None__cache_length_pattern=tile__cache_strategy_pattern=tile__global_tokens=4__history_window_size=1__max_cache_length={frac}__recent_window=10'\n",
    "\n",
    "h2o_df = []\n",
    "\n",
    "for frac in [0.1, 0.3, 0.5, 0.7, 0.9]:\n",
    "    subdir = subdir_template.format(frac=frac)\n",
    "    task_json = os.path.join(root, subdir, f'{task}_metrics.json')\n",
    "    with open(task_json) as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    # get the metrics\n",
    "    acc = data['Accuracy']\n",
    "    exact_match = data['ExactMatch']\n",
    "    cache_mem_gb = data['cache_memory_gb']\n",
    "    compress_ratio = data['compression_ratio_avg']\n",
    "    decode_toks_per_sec_top_10p = data['decode_toks_per_sec_top_10p']\n",
    "\n",
    "    h2o_df.append({\n",
    "        'strategy': strategy,\n",
    "        'cache_size': frac,\n",
    "        'accuracy': acc,\n",
    "        'exact_match': exact_match,\n",
    "        'compress_ratio_avg': compress_ratio,\n",
    "        'cache_mem_gb': cache_mem_gb,\n",
    "        'decode_toks_per_sec_top_10p': decode_toks_per_sec_top_10p,\n",
    "    })\n",
    "\n",
    "h2o_df = pd.DataFrame(h2o_df)\n",
    "h2o_df.to_csv(f'ICLR/h2o_{task}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = 'medqa'\n",
    "\n",
    "# FastGen\n",
    "strategy = 'fastgen'\n",
    "root = 'ICLR/results_nov16_2/results/Meta-Llama-3-8B-Instruct/hybrid/'\n",
    "subdir_template = 'cache_bits=None__cache_length_pattern=tile__cache_strategy_pattern=tile__global_tokens=4__hybrid_strategies=specialx1,special_puncx1,special_punc_heavy_hitterx1,special_punc_heavy_hitter_windowx1,fullx1__max_cache_length=1__min_recovery_frac={frac}'\n",
    "fastgen_df = []\n",
    "for frac in [0.1, 0.3, 0.5, 0.7, 0.9]:\n",
    "    subdir = subdir_template.format(frac=frac)\n",
    "    task_json = os.path.join(root, subdir, f'{task}_metrics.json')\n",
    "    with open(task_json) as f:\n",
    "        data = json.load(f)\n",
    "    # get the metrics\n",
    "    bert_precision = data['BertScore_precision']\n",
    "    bert_recall = data['BertScore_recall']\n",
    "    bert_f1 = data['BertScore_f1']\n",
    "    rouge_1 = data['Rouge_rouge1']\n",
    "    rouge_2 = data['Rouge_rouge2']\n",
    "    rouge_L = data['Rouge_rougeL']\n",
    "    rouge_Lsum = data['Rouge_rougeLsum']\n",
    "    chatgpt_rouge = data['ChatGPT-Rouge_chatgpt_rouge']\n",
    "    chatgpt_coherent = data['ChatGPTJudge_coherent']\n",
    "    chatgpt_faithful = data['ChatGPTJudge_faithful']\n",
    "    chatgpt_helpful = data['ChatGPTJudge_helpful']\n",
    "    cache_mem_gb = data['cache_memory_gb']\n",
    "    compress_ratio = data['compression_ratio_avg']\n",
    "    decode_toks_per_sec_top_10p = data['decode_toks_per_sec_top_10p']\n",
    "    cache_size = frac\n",
    "    # append to the dataframe\n",
    "    fastgen_df.append({\n",
    "        'strategy': strategy,\n",
    "        'cache_size': cache_size,\n",
    "        'bert_precision': bert_precision,\n",
    "        'bert_recall': bert_recall,\n",
    "        'bert_f1': bert_f1,\n",
    "        'rouge_1': rouge_1,\n",
    "        'rouge_2': rouge_2,\n",
    "        'rouge_L': rouge_L,\n",
    "        'rouge_Lsum': rouge_Lsum,\n",
    "        'chatgpt_rouge': chatgpt_rouge,\n",
    "        'chatgpt_coherent': chatgpt_coherent,\n",
    "        'chatgpt_faithful': chatgpt_faithful,\n",
    "        'chatgpt_helpful': chatgpt_helpful,\n",
    "        'compress_ratio_avg': compress_ratio,\n",
    "        'cache_mem_gb': cache_mem_gb,\n",
    "        'decode_toks_per_sec_top_10p': decode_toks_per_sec_top_10p,\n",
    "    })\n",
    "fastgen_df = pd.DataFrame(fastgen_df)\n",
    "fastgen_df.to_csv(f'ICLR/fastgen_{task}.csv', index=False)\n",
    "\n",
    "# H2O\n",
    "strategy = 'h2o'\n",
    "root = 'ICLR/results_nov16_2/results/Meta-Llama-3-8B-Instruct/heavy_hitter/'\n",
    "subdir_template = 'attn_thresholding=False__cache_bits=None__cache_length_pattern=tile__cache_strategy_pattern=tile__global_tokens=4__history_window_size=1__max_cache_length={frac}__recent_window=10'\n",
    "h2o_df = []\n",
    "for frac in [0.1, 0.3, 0.5, 0.7, 0.9]:\n",
    "    subdir = subdir_template.format(frac=frac)\n",
    "    task_json = os.path.join(root, subdir, f'{task}_metrics.json')\n",
    "    with open(task_json) as f:\n",
    "        data = json.load(f)\n",
    "    # get the metrics\n",
    "    bert_precision = data['BertScore_precision']\n",
    "    bert_recall = data['BertScore_recall']\n",
    "    bert_f1 = data['BertScore_f1']\n",
    "    rouge_1 = data['Rouge_rouge1']\n",
    "    rouge_2 = data['Rouge_rouge2']\n",
    "    rouge_L = data['Rouge_rougeL']\n",
    "    rouge_Lsum = data['Rouge_rougeLsum']\n",
    "    chatgpt_rouge = data['ChatGPT-Rouge_chatgpt_rouge']\n",
    "    chatgpt_coherent = data['ChatGPTJudge_coherent']\n",
    "    chatgpt_faithful = data['ChatGPTJudge_faithful']\n",
    "    chatgpt_helpful = data['ChatGPTJudge_helpful']\n",
    "    cache_mem_gb = data['cache_memory_gb']\n",
    "    compress_ratio = data['compression_ratio_avg']\n",
    "    decode_toks_per_sec_top_10p = data['decode_toks_per_sec_top_10p']\n",
    "    cache_size = frac\n",
    "    # append to the dataframe\n",
    "    h2o_df.append({\n",
    "        'strategy': strategy,\n",
    "        'cache_size': cache_size,\n",
    "        'bert_precision': bert_precision,\n",
    "        'bert_recall': bert_recall,\n",
    "        'bert_f1': bert_f1,\n",
    "        'rouge_1': rouge_1,\n",
    "        'rouge_2': rouge_2,\n",
    "        'rouge_L': rouge_L,\n",
    "        'rouge_Lsum': rouge_Lsum,\n",
    "        'chatgpt_rouge': chatgpt_rouge,\n",
    "        'chatgpt_coherent': chatgpt_coherent,\n",
    "        'chatgpt_faithful': chatgpt_faithful,\n",
    "        'chatgpt_helpful': chatgpt_helpful,\n",
    "        'compress_ratio_avg': compress_ratio,\n",
    "        'cache_mem_gb': cache_mem_gb,\n",
    "        'decode_toks_per_sec_top_10p': decode_toks_per_sec_top_10p,\n",
    "    })\n",
    "h2o_df = pd.DataFrame(h2o_df)\n",
    "h2o_df.to_csv(f'ICLR/h2o_{task}.csv', index=False)\n",
    "\n",
    "# Scissorhands\n",
    "strategy = 'scissorhands'\n",
    "root = 'ICLR/results_nov16_2/results/Meta-Llama-3-8B-Instruct/heavy_hitter/'\n",
    "subdir_template = 'attn_thresholding=True__cache_bits=None__cache_length_pattern=tile__cache_strategy_pattern=tile__global_tokens=4__history_window_size=400__max_cache_length={frac}__recent_window=10'\n",
    "scissorhands_df = []\n",
    "for frac in [0.1, 0.3, 0.5, 0.7, 0.9]:\n",
    "    subdir = subdir_template.format(frac=frac)\n",
    "    task_json = os.path.join(root, subdir, f'{task}_metrics.json')\n",
    "    with open(task_json) as f:\n",
    "        data = json.load(f)\n",
    "    # get the metrics\n",
    "    bert_precision = data['BertScore_precision']\n",
    "    bert_recall = data['BertScore_recall']\n",
    "    bert_f1 = data['BertScore_f1']\n",
    "    rouge_1 = data['Rouge_rouge1']\n",
    "    rouge_2 = data['Rouge_rouge2']\n",
    "    rouge_L = data['Rouge_rougeL']\n",
    "    rouge_Lsum = data['Rouge_rougeLsum']\n",
    "    chatgpt_rouge = data['ChatGPT-Rouge_chatgpt_rouge']\n",
    "    chatgpt_coherent = data['ChatGPTJudge_coherent']\n",
    "    chatgpt_faithful = data['ChatGPTJudge_faithful']\n",
    "    chatgpt_helpful = data['ChatGPTJudge_helpful']\n",
    "    cache_mem_gb = data['cache_memory_gb']\n",
    "    compress_ratio = data['compression_ratio_avg']\n",
    "    decode_toks_per_sec_top_10p = data['decode_toks_per_sec_top_10p']\n",
    "    cache_size = frac\n",
    "    # append to the dataframe\n",
    "    scissorhands_df.append({\n",
    "        'strategy': strategy,\n",
    "        'cache_size': cache_size,\n",
    "        'bert_precision': bert_precision,\n",
    "        'bert_recall': bert_recall,\n",
    "        'bert_f1': bert_f1,\n",
    "        'rouge_1': rouge_1,\n",
    "        'rouge_2': rouge_2,\n",
    "        'rouge_L': rouge_L,\n",
    "        'rouge_Lsum': rouge_Lsum,\n",
    "        'chatgpt_rouge': chatgpt_rouge,\n",
    "        'chatgpt_coherent': chatgpt_coherent,\n",
    "        'chatgpt_faithful': chatgpt_faithful,\n",
    "        'chatgpt_helpful': chatgpt_helpful,\n",
    "        'compress_ratio_avg': compress_ratio,\n",
    "        'cache_mem_gb': cache_mem_gb,\n",
    "        'decode_toks_per_sec_top_10p': decode_toks_per_sec_top_10p,\n",
    "    })\n",
    "scissorhands_df = pd.DataFrame(scissorhands_df)\n",
    "scissorhands_df.to_csv(f'ICLR/scissorhands_{task}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = 'medqa_mc'\n",
    "\n",
    "# FastGen\n",
    "strategy = 'fastgen'\n",
    "root = 'ICLR/results_fastgen/results/Meta-Llama-3-8B-Instruct/hybrid/'\n",
    "subdir_template = 'cache_bits=None__cache_length_pattern=tile__cache_strategy_pattern=tile__global_tokens=4__hybrid_strategies=specialx1,special_puncx1,special_punc_heavy_hitterx1,special_punc_heavy_hitter_windowx1,fullx1__max_cache_length=1__min_recovery_frac={frac}'\n",
    "\n",
    "fastgen_df = []\n",
    "\n",
    "for frac in [0.1, 0.3, 0.5, 0.7, 0.9]:\n",
    "    subdir = subdir_template.format(frac=frac)\n",
    "    task_json = os.path.join(root, subdir, f'{task}_metrics.json')\n",
    "    with open(task_json) as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    # get the metrics\n",
    "    acc = data['Accuracy']\n",
    "    cache_mem_gb = data['cache_memory_gb']\n",
    "    compress_ratio = data['compression_ratio_avg']\n",
    "    decode_toks_per_sec_top_10p = data['decode_toks_per_sec_top_10p']\n",
    "\n",
    "    fastgen_df.append({\n",
    "        'strategy': strategy,\n",
    "        'cache_size': frac,\n",
    "        'accuracy': acc,\n",
    "        'compress_ratio_avg': compress_ratio,\n",
    "        'cache_mem_gb': cache_mem_gb,\n",
    "        'decode_toks_per_sec_top_10p': decode_toks_per_sec_top_10p,\n",
    "    })\n",
    "\n",
    "fastgen_df = pd.DataFrame(fastgen_df)\n",
    "fastgen_df.to_csv(f'ICLR/fastgen_{task}.csv', index=False)\n",
    "\n",
    "# Scissorhands\n",
    "strategy = 'scissorhands'\n",
    "root = 'ICLR/results_scissorhands/results/Meta-Llama-3-8B-Instruct/heavy_hitter/'\n",
    "subdir_template = 'attn_thresholding=True__cache_bits=None__cache_length_pattern=tile__cache_strategy_pattern=tile__global_tokens=4__history_window_size=400__max_cache_length={frac}__recent_window=10'\n",
    "scissorhands_df = []\n",
    "\n",
    "for frac in [0.1, 0.3, 0.5, 0.7, 0.9]:\n",
    "    subdir = subdir_template.format(frac=frac)\n",
    "    task_json = os.path.join(root, subdir, f'{task}_metrics.json')\n",
    "    with open(task_json) as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    # get the metrics\n",
    "    acc = data['Accuracy']\n",
    "    cache_mem_gb = data['cache_memory_gb']\n",
    "    compress_ratio = data['compression_ratio_avg']\n",
    "    decode_toks_per_sec_top_10p = data['decode_toks_per_sec_top_10p']\n",
    "\n",
    "    scissorhands_df.append({\n",
    "        'strategy': strategy,\n",
    "        'cache_size': frac,\n",
    "        'accuracy': acc,\n",
    "        'compress_ratio_avg': compress_ratio,\n",
    "        'cache_mem_gb': cache_mem_gb,\n",
    "        'decode_toks_per_sec_top_10p': decode_toks_per_sec_top_10p,\n",
    "    })\n",
    "\n",
    "scissorhands_df = pd.DataFrame(scissorhands_df)\n",
    "scissorhands_df.to_csv(f'ICLR/scissorhands_{task}.csv', index=False)\n",
    "\n",
    "# H2O\n",
    "strategy = 'h2o'\n",
    "root = 'ICLR/results_h2o/results/Meta-Llama-3-8B-Instruct/heavy_hitter/'\n",
    "subdir_template = 'attn_thresholding=False__cache_bits=None__cache_length_pattern=tile__cache_strategy_pattern=tile__global_tokens=4__history_window_size=1__max_cache_length={frac}__recent_window=10'\n",
    "h2o_df = []\n",
    "\n",
    "for frac in [0.1, 0.3, 0.5, 0.7, 0.9]:\n",
    "    subdir = subdir_template.format(frac=frac)\n",
    "    task_json = os.path.join(root, subdir, f'{task}_metrics.json')\n",
    "    with open(task_json) as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    # get the metrics\n",
    "    acc = data['Accuracy']\n",
    "    cache_mem_gb = data['cache_memory_gb']\n",
    "    compress_ratio = data['compression_ratio_avg']\n",
    "    decode_toks_per_sec_top_10p = data['decode_toks_per_sec_top_10p']\n",
    "\n",
    "    h2o_df.append({\n",
    "        'strategy': strategy,\n",
    "        'cache_size': frac,\n",
    "        'accuracy': acc,\n",
    "        'compress_ratio_avg': compress_ratio,\n",
    "        'cache_mem_gb': cache_mem_gb,\n",
    "        'decode_toks_per_sec_top_10p': decode_toks_per_sec_top_10p,\n",
    "    })\n",
    "\n",
    "h2o_df = pd.DataFrame(h2o_df)\n",
    "h2o_df.to_csv(f'ICLR/h2o_{task}.csv', index=False)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'ICLR/results_nov16_2/results/Meta-Llama-3-8B-Instruct/hybrid/cache_bits=None__cache_length_pattern=tile__cache_strategy_pattern=tile__global_tokens=4__hybrid_strategies=specialx1,special_puncx1,special_punc_heavy_hitterx1,special_punc_heavy_hitter_windowx1,fullx1__max_cache_length=1__min_recovery_frac=0.1/rulercwe_metrics.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[44], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m subdir \u001b[38;5;241m=\u001b[39m subdir_template\u001b[38;5;241m.\u001b[39mformat(frac\u001b[38;5;241m=\u001b[39mfrac)\n\u001b[1;32m     12\u001b[0m task_json \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(root2, subdir, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtask\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_metrics.json\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 13\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtask_json\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m     14\u001b[0m     data \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(f)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# get the metrics\u001b[39;00m\n",
      "File \u001b[0;32m~/github/gather_results/.venv/lib/python3.11/site-packages/IPython/core/interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    322\u001b[0m     )\n\u001b[0;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'ICLR/results_nov16_2/results/Meta-Llama-3-8B-Instruct/hybrid/cache_bits=None__cache_length_pattern=tile__cache_strategy_pattern=tile__global_tokens=4__hybrid_strategies=specialx1,special_puncx1,special_punc_heavy_hitterx1,special_punc_heavy_hitter_windowx1,fullx1__max_cache_length=1__min_recovery_frac=0.1/rulercwe_metrics.json'"
     ]
    }
   ],
   "source": [
    "task = 'rulercwe'\n",
    "\n",
    "# FastGen\n",
    "strategy = 'fastgen'\n",
    "root = 'ICLR/results_fastgen/results/Meta-Llama-3-8B-Instruct/hybrid/'\n",
    "subdir_template = 'cache_bits=None__cache_length_pattern=tile__cache_strategy_pattern=tile__global_tokens=4__hybrid_strategies=specialx1,special_puncx1,special_punc_heavy_hitterx1,special_punc_heavy_hitter_windowx1,fullx1__max_cache_length=1__min_recovery_frac={frac}'\n",
    "fastgen_df = []\n",
    "\n",
    "for frac in [0.1, 0.9]:\n",
    "    root2 = 'ICLR/results_????/results/Meta-Llama-3-8B-Instruct/hybrid/'\n",
    "    subdir = subdir_template.format(frac=frac)\n",
    "    task_json = os.path.join(root2, subdir, f'{task}_metrics.json')\n",
    "    with open(task_json) as f:\n",
    "        data = json.load(f)\n",
    "    # get the metrics\n",
    "    string_match = data['StringMatch_score']\n",
    "    cache_mem_gb = data['cache_memory_gb']\n",
    "    compress_ratio = data['compression_ratio_avg']\n",
    "    decode_toks_per_sec_top_10p = data['decode_toks_per_sec_top_10p']\n",
    "    fastgen_df.append({\n",
    "        'strategy': strategy,\n",
    "        'cache_size': frac,\n",
    "        'string_match': string_match,\n",
    "        'compress_ratio_avg': compress_ratio,\n",
    "        'cache_mem_gb': cache_mem_gb,\n",
    "        'decode_toks_per_sec_top_10p': decode_toks_per_sec_top_10p,\n",
    "    })\n",
    "\n",
    "for frac in [0.3, 0.5, 0.7]:\n",
    "    subdir = subdir_template.format(frac=frac)\n",
    "    task_json = os.path.join(root, subdir, f'{task}_metrics.json')\n",
    "    with open(task_json) as f:\n",
    "        data = json.load(f)\n",
    "    # get the metrics\n",
    "    string_match = data['StringMatch_score']\n",
    "    cache_mem_gb = data['cache_memory_gb']\n",
    "    compress_ratio = data['compression_ratio_avg']\n",
    "    decode_toks_per_sec_top_10p = data['decode_toks_per_sec_top_10p']\n",
    "    fastgen_df.append({\n",
    "        'strategy': strategy,\n",
    "        'cache_size': frac,\n",
    "        'string_match': string_match,\n",
    "        'compress_ratio_avg': compress_ratio,\n",
    "        'cache_mem_gb': cache_mem_gb,\n",
    "        'decode_toks_per_sec_top_10p': decode_toks_per_sec_top_10p,\n",
    "    })\n",
    "fastgen_df = pd.DataFrame(fastgen_df)\n",
    "fastgen_df.to_csv(f'ICLR/fastgen_{task}.csv', index=False)\n",
    "\n",
    "# Scissorhands\n",
    "strategy = 'scissorhands'\n",
    "root = 'ICLR/results_scissorhands/results/Meta-Llama-3-8B-Instruct/heavy_hitter/'\n",
    "subdir_template = 'attn_thresholding=True__cache_bits=None__cache_length_pattern=tile__cache_strategy_pattern=tile__global_tokens=4__history_window_size=400__max_cache_length={frac}__recent_window=10'\n",
    "scissorhands_df = []\n",
    "for frac in [0.1, 0.3, 0.5, 0.7, 0.9]:\n",
    "    subdir = subdir_template.format(frac=frac)\n",
    "    task_json = os.path.join(root, subdir, f'{task}_metrics.json')\n",
    "    with open(task_json) as f:\n",
    "        data = json.load(f)\n",
    "    # get the metrics\n",
    "    string_match = data['StringMatch_score']\n",
    "    cache_mem_gb = data['cache_memory_gb']\n",
    "    compress_ratio = data['compression_ratio_avg']\n",
    "    decode_toks_per_sec_top_10p = data['decode_toks_per_sec_top_10p']\n",
    "    scissorhands_df.append({\n",
    "        'strategy': strategy,\n",
    "        'cache_size': frac,\n",
    "        'string_match': string_match,\n",
    "        'compress_ratio_avg': compress_ratio,\n",
    "        'cache_mem_gb': cache_mem_gb,\n",
    "        'decode_toks_per_sec_top_10p': decode_toks_per_sec_top_10p,\n",
    "    })\n",
    "scissorhands_df = pd.DataFrame(scissorhands_df)\n",
    "scissorhands_df.to_csv(f'ICLR/scissorhands_{task}.csv', index=False)\n",
    "\n",
    "# H2O\n",
    "strategy = 'h2o'\n",
    "root = 'ICLR/results_h2o/results/Meta-Llama-3-8B-Instruct/heavy_hitter/'\n",
    "subdir_template = 'attn_thresholding=False__cache_bits=None__cache_length_pattern=tile__cache_strategy_pattern=tile__global_tokens=4__history_window_size=1__max_cache_length={frac}__recent_window=10'\n",
    "h2o_df = []\n",
    "for frac in [0.1, 0.3, 0.5, 0.7, 0.9]:\n",
    "    subdir = subdir_template.format(frac=frac)\n",
    "    task_json = os.path.join(root, subdir, f'{task}_metrics.json')\n",
    "    with open(task_json) as f:\n",
    "        data = json.load(f)\n",
    "    # get the metrics\n",
    "    string_match = data['StringMatch_score']\n",
    "    cache_mem_gb = data['cache_memory_gb']\n",
    "    compress_ratio = data['compression_ratio_avg']\n",
    "    decode_toks_per_sec_top_10p = data['decode_toks_per_sec_top_10p']\n",
    "    h2o_df.append({\n",
    "        'strategy': strategy,\n",
    "        'cache_size': frac,\n",
    "        'string_match': string_match,\n",
    "        'compress_ratio_avg': compress_ratio,\n",
    "        'cache_mem_gb': cache_mem_gb,\n",
    "        'decode_toks_per_sec_top_10p': decode_toks_per_sec_top_10p,\n",
    "    })\n",
    "h2o_df = pd.DataFrame(h2o_df)\n",
    "h2o_df.to_csv(f'ICLR/h2o_{task}.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = \"rulerniah\"\n",
    "\n",
    "# FastGen\n",
    "strategy = 'h2o'\n",
    "root = 'ICLR/results_nov_15/results/Meta-Llama-3-8B-Instruct/heavy_hitter/'\n",
    "subdir_template = 'attn_thresholding=False__cache_bits=None__cache_length_pattern=tile__cache_strategy_pattern=tile__global_tokens=4__history_window_size=1__max_cache_length={frac}__recent_window=10'\n",
    "h2o_df = []\n",
    "for frac in [0.1, 0.3, 0.5, 0.7, 0.9]:\n",
    "    subdir = subdir_template.format(frac=frac)\n",
    "    task_json = os.path.join(root, subdir, f'{task}_metrics.json')\n",
    "    with open(task_json) as f:\n",
    "        data = json.load(f)\n",
    "    # get the metrics\n",
    "    string_match = data['StringMatch_score']\n",
    "    cache_mem_gb = data['cache_memory_gb']\n",
    "    compress_ratio = data['compression_ratio_avg']\n",
    "    decode_toks_per_sec_top_10p = data['decode_toks_per_sec_top_10p']\n",
    "    h2o_df.append({\n",
    "        'strategy': strategy,\n",
    "        'cache_size': frac,\n",
    "        'string_match': string_match,\n",
    "        'compress_ratio_avg': compress_ratio,\n",
    "        'cache_mem_gb': cache_mem_gb,\n",
    "        'decode_toks_per_sec_top_10p': decode_toks_per_sec_top_10p,\n",
    "    })\n",
    "h2o_df = pd.DataFrame(h2o_df)\n",
    "h2o_df.to_csv(f'ICLR/h2o_{task}.csv', index=False)\n",
    "\n",
    "# Scissorhands\n",
    "strategy = 'scissorhands'\n",
    "root = 'ICLR/results_nov_15/results/Meta-Llama-3-8B-Instruct/heavy_hitter/'\n",
    "subdir_template = 'attn_thresholding=True__cache_bits=None__cache_length_pattern=tile__cache_strategy_pattern=tile__global_tokens=4__history_window_size=400__max_cache_length={frac}__recent_window=10'\n",
    "scissorhands_df = []\n",
    "for frac in [0.1, 0.3, 0.5, 0.7, 0.9]:\n",
    "    subdir = subdir_template.format(frac=frac)\n",
    "    task_json = os.path.join(root, subdir, f'{task}_metrics.json')\n",
    "    with open(task_json) as f:\n",
    "        data = json.load(f)\n",
    "    # get the metrics\n",
    "    string_match = data['StringMatch_score']\n",
    "    cache_mem_gb = data['cache_memory_gb']\n",
    "    compress_ratio = data['compression_ratio_avg']\n",
    "    decode_toks_per_sec_top_10p = data['decode_toks_per_sec_top_10p']\n",
    "    scissorhands_df.append({\n",
    "        'strategy': strategy,\n",
    "        'cache_size': frac,\n",
    "        'string_match': string_match,\n",
    "        'compress_ratio_avg': compress_ratio,\n",
    "        'cache_mem_gb': cache_mem_gb,\n",
    "        'decode_toks_per_sec_top_10p': decode_toks_per_sec_top_10p,\n",
    "    })\n",
    "scissorhands_df = pd.DataFrame(scissorhands_df)\n",
    "scissorhands_df.to_csv(f'ICLR/scissorhands_{task}.csv', index=False)\n",
    "\n",
    "# FastGen\n",
    "strategy = 'fastgen'\n",
    "root = 'ICLR/results_nov16_2/results/Meta-Llama-3-8B-Instruct/hybrid/'\n",
    "subdir_template = 'cache_bits=None__cache_length_pattern=tile__cache_strategy_pattern=tile__global_tokens=4__hybrid_strategies=specialx1,special_puncx1,special_punc_heavy_hitterx1,special_punc_heavy_hitter_windowx1,fullx1__max_cache_length=1__min_recovery_frac={frac}'\n",
    "fastgen_df = []\n",
    "for frac in [0.1, 0.3, 0.5, 0.7, 0.9]:\n",
    "    subdir = subdir_template.format(frac=frac)\n",
    "    task_json = os.path.join(root, subdir, f'{task}_metrics.json')\n",
    "    with open(task_json) as f:\n",
    "        data = json.load(f)\n",
    "    # get the metrics\n",
    "    string_match = data['StringMatch_score']\n",
    "    cache_mem_gb = data['cache_memory_gb']\n",
    "    compress_ratio = data['compression_ratio_avg']\n",
    "    decode_toks_per_sec_top_10p = data['decode_toks_per_sec_top_10p']\n",
    "    fastgen_df.append({\n",
    "        'strategy': strategy,\n",
    "        'cache_size': frac,\n",
    "        'string_match': string_match,\n",
    "        'compress_ratio_avg': compress_ratio,\n",
    "        'cache_mem_gb': cache_mem_gb,\n",
    "        'decode_toks_per_sec_top_10p': decode_toks_per_sec_top_10p,\n",
    "    })\n",
    "fastgen_df = pd.DataFrame(fastgen_df)\n",
    "fastgen_df.to_csv(f'ICLR/fastgen_{task}.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = \"gsm\"\n",
    "\n",
    "# L2\n",
    "strategy = 'l2'\n",
    "root = 'results_gsm_final/l2/'\n",
    "subdir_template = 'cache_bits=None__cache_length_pattern=tile__cache_strategy_pattern=tile__global_tokens=4__max_cache_length={frac}__recent_window=10'\n",
    "l2_df = []\n",
    "for frac in [0.1, 0.3, 0.5, 0.7, 0.9]:\n",
    "    subdir = subdir_template.format(frac=frac)\n",
    "    task_json = os.path.join(root, subdir, f'{task}_metrics.json')\n",
    "    with open(task_json) as f:\n",
    "        data = json.load(f)\n",
    "    # get the metrics\n",
    "    bert_precision = data['BertScore_precision']\n",
    "    bert_recall = data['BertScore_recall']\n",
    "    bert_f1 = data['BertScore_f1']\n",
    "    rouge_1 = data['Rouge_rouge1']\n",
    "    rouge_2 = data['Rouge_rouge2']\n",
    "    rouge_L = data['Rouge_rougeL']\n",
    "    rouge_Lsum = data['Rouge_rougeLsum']\n",
    "    chatgpt_rouge = data['ChatGPT-Rouge_chatgpt_rouge']\n",
    "    chatgpt_coherent = data['ChatGPTJudge_coherent']\n",
    "    chatgpt_faithful = data['ChatGPTJudge_faithful']\n",
    "    chatgpt_helpful = data['ChatGPTJudge_helpful']\n",
    "    cache_mem_gb = data['cache_memory_gb']\n",
    "    compress_ratio = data['compression_ratio_avg']\n",
    "    decode_toks_per_sec_top_10p = data['decode_toks_per_sec_top_10p']\n",
    "    l2_df.append({\n",
    "        'strategy': strategy,\n",
    "        'cache_size': frac,\n",
    "        'bert_precision': bert_precision,\n",
    "        'bert_recall': bert_recall,\n",
    "        'bert_f1': bert_f1,\n",
    "        'rouge_1': rouge_1,\n",
    "        'rouge_2': rouge_2,\n",
    "        'rouge_L': rouge_L,\n",
    "        'rouge_Lsum': rouge_Lsum,\n",
    "        'chatgpt_rouge': chatgpt_rouge,\n",
    "        'chatgpt_coherent': chatgpt_coherent,\n",
    "        'chatgpt_faithful': chatgpt_faithful,\n",
    "        'chatgpt_helpful': chatgpt_helpful,\n",
    "        'compress_ratio_avg': compress_ratio,\n",
    "        'cache_mem_gb': cache_mem_gb,\n",
    "        'decode_toks_per_sec_top_10p': decode_toks_per_sec_top_10p,\n",
    "    })\n",
    "l2_df = pd.DataFrame(l2_df)\n",
    "l2_df.to_csv(f'ICLR/l2_{task}.csv', index=False)\n",
    "\n",
    "# LSH\n",
    "strategy = 'lsh'\n",
    "root = 'results_gsm_final/lsh/'\n",
    "subdir_template = 'cache_bits=None__cache_length_pattern=tile__cache_strategy_pattern=tile__global_tokens=4__lsh_dim=16__max_cache_length={frac}__recent_window=10'\n",
    "lsh_df = []\n",
    "for frac in [0.1, 0.3, 0.5, 0.7, 0.9]:\n",
    "    subdir = subdir_template.format(frac=frac)\n",
    "    task_json = os.path.join(root, subdir, f'{task}_metrics.json')\n",
    "    with open(task_json) as f:\n",
    "        data = json.load(f)\n",
    "    # get the metrics\n",
    "    bert_precision = data['BertScore_precision']\n",
    "    bert_recall = data['BertScore_recall']\n",
    "    bert_f1 = data['BertScore_f1']\n",
    "    rouge_1 = data['Rouge_rouge1']\n",
    "    rouge_2 = data['Rouge_rouge2']\n",
    "    rouge_L = data['Rouge_rougeL']\n",
    "    rouge_Lsum = data['Rouge_rougeLsum']\n",
    "    chatgpt_rouge = data['ChatGPT-Rouge_chatgpt_rouge']\n",
    "    chatgpt_coherent = data['ChatGPTJudge_coherent']\n",
    "    chatgpt_faithful = data['ChatGPTJudge_faithful']\n",
    "    chatgpt_helpful = data['ChatGPTJudge_helpful']\n",
    "    cache_mem_gb = data['cache_memory_gb']\n",
    "    compress_ratio = data['compression_ratio_avg']\n",
    "    decode_toks_per_sec_top_10p = data['decode_toks_per_sec_top_10p']\n",
    "    lsh_df.append({\n",
    "        'strategy': strategy,\n",
    "        'cache_size': frac,\n",
    "        'bert_precision': bert_precision,\n",
    "        'bert_recall': bert_recall,\n",
    "        'bert_f1': bert_f1,\n",
    "        'rouge_1': rouge_1,\n",
    "        'rouge_2': rouge_2,\n",
    "        'rouge_L': rouge_L,\n",
    "        'rouge_Lsum': rouge_Lsum,\n",
    "        'chatgpt_rouge': chatgpt_rouge,\n",
    "        'chatgpt_coherent': chatgpt_coherent,\n",
    "        'chatgpt_faithful': chatgpt_faithful,\n",
    "        'chatgpt_helpful': chatgpt_helpful,\n",
    "        'compress_ratio_avg': compress_ratio,\n",
    "        'cache_mem_gb': cache_mem_gb,\n",
    "        'decode_toks_per_sec_top_10p': decode_toks_per_sec_top_10p,\n",
    "    })\n",
    "lsh_df = pd.DataFrame(lsh_df)\n",
    "lsh_df.to_csv(f'ICLR/lsh_{task}.csv', index=False)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
